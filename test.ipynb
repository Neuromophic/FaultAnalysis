{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.getcwd())\n",
    "sys.path.append(os.path.join(os.getcwd(), 'utils'))\n",
    "from configuration import *\n",
    "import torch\n",
    "import pprint\n",
    "import pNN\n",
    "from utils import *\n",
    "\n",
    "args = parser.parse_args([])\n",
    "args.e_train = 0.05\n",
    "args.N_train = 10\n",
    "args.e_fault = 1\n",
    "args.N_fault = 20\n",
    "args.SEED = 0\n",
    "args.report_freq = 1\n",
    "args = FormulateArgs(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training network on device: cpu.\n",
      "{'N_class': 2,\n",
      " 'N_feature': 6,\n",
      " 'N_test': 25,\n",
      " 'N_train': 70,\n",
      " 'N_valid': 23,\n",
      " 'dataname': 'acuteinflammation'}\n",
      "Training setup: data_00_acuteinflammation_seed_00_epsilon:0.05.model.\n"
     ]
    }
   ],
   "source": [
    "print(f'Training network on device: {args.DEVICE}.')\n",
    "MakeFolder(args)\n",
    "\n",
    "train_loader, datainfo = GetDataLoader(args, 'train')\n",
    "valid_loader, datainfo = GetDataLoader(args, 'valid')\n",
    "test_loader, datainfo = GetDataLoader(args, 'test')\n",
    "pprint.pprint(datainfo)\n",
    "\n",
    "SetSeed(args.SEED)\n",
    "\n",
    "setup = f\"data_{args.DATASET:02d}_{datainfo['dataname']}_seed_{args.SEED:02d}_epsilon_{args.e_train}_faults_{args.e_fault:1d}.model\"\n",
    "print(f'Training setup: {setup}.')\n",
    "\n",
    "msglogger = GetMessageLogger(args, setup)\n",
    "msglogger.info(f'Training network on device: {args.DEVICE}.')\n",
    "msglogger.info(f'Training setup: {setup}.')\n",
    "msglogger.info(datainfo)\n",
    "\n",
    "topology = [datainfo['N_feature']] + args.hidden + [datainfo['N_class']]\n",
    "msglogger.info(f'Topology of the network: {topology}.')\n",
    "\n",
    "pnn = pNN.pNN(topology, args).to(args.DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch:      0 | Train loss: 7.4705e+00 | Valid loss: 1.8939e+01 | Train acc: 0.4983 ± 0.0296 | Valid acc: 0.5339 ± 0.1350 | patience:   0 | lr: 0.1 | Epoch time: 3.8 |\n",
      "| Epoch:      1 | Train loss: 6.9889e+00 | Valid loss: 6.6272e+00 | Train acc: 0.5060 ± 0.0565 | Valid acc: 0.6239 ± 0.1255 | patience:   0 | lr: 0.1 | Epoch time: 3.8 |\n",
      "| Epoch:      2 | Train loss: 6.7421e+00 | Valid loss: 6.1706e+00 | Train acc: 0.5757 ± 0.0912 | Valid acc: 0.7061 ± 0.1396 | patience:   0 | lr: 0.1 | Epoch time: 3.8 |\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(pnn\u001b[38;5;241m.\u001b[39mGetParam(), lr\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mLR)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mPROGRESSIVE:\n\u001b[0;32m----> 5\u001b[0m     pnn, best \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_pnn_progressive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlossfunction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsglogger\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mUUID\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msetup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m      7\u001b[0m     pnn, best \u001b[38;5;241m=\u001b[39m train_pnn(pnn, train_loader, valid_loader, lossfunction, optimizer, args, msglogger, UUID\u001b[38;5;241m=\u001b[39msetup)\n",
      "File \u001b[0;32m~/Desktop/TECO/24_Fault_Analysis/utils/training.py:49\u001b[0m, in \u001b[0;36mtrain_pnn_progressive\u001b[0;34m(nn, train_loader, valid_loader, lossfunction, optimizer, args, logger, UUID)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x_valid, y_valid \u001b[38;5;129;01min\u001b[39;00m valid_loader:\n\u001b[1;32m     47\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhyperparameters in printed neural network for validation :\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mepoch : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m-6d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m |\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 49\u001b[0m     L_valid \u001b[38;5;241m=\u001b[39m lossfunction(\u001b[43mnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_valid\u001b[49m\u001b[43m)\u001b[49m, y_valid)\n\u001b[1;32m     50\u001b[0m     valid_result \u001b[38;5;241m=\u001b[39m evaluator(nn, x_valid, y_valid)\n\u001b[1;32m     51\u001b[0m     valid_acc, valid_std, valid_power, valid_area \u001b[38;5;241m=\u001b[39m valid_result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m'\u001b[39m], valid_result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd\u001b[39m\u001b[38;5;124m'\u001b[39m], valid_result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpower\u001b[39m\u001b[38;5;124m'\u001b[39m], valid_result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marea\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/ML/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/TECO/24_Fault_Analysis/pNN.py:270\u001b[0m, in \u001b[0;36mpNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mSampleFault()\n\u001b[1;32m    269\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mrepeat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mN_fault, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mN, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 270\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ML/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/ML/lib/python3.8/site-packages/torch/nn/modules/container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 141\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/ML/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/TECO/24_Fault_Analysis/pNN.py:84\u001b[0m, in \u001b[0;36mpLayer.forward\u001b[0;34m(self, a_previous)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, a_previous):\n\u001b[1;32m     83\u001b[0m     z_new \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mMAC(a_previous)\n\u001b[0;32m---> 84\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmac_power \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMAC_power\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma_previous\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz_new\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mACT\u001b[38;5;241m.\u001b[39mMask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mFaultMaskACT\n\u001b[1;32m     86\u001b[0m     a_new \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mACT(z_new)\n",
      "File \u001b[0;32m~/Desktop/TECO/24_Fault_Analysis/pNN.py:122\u001b[0m, in \u001b[0;36mpLayer.MAC_power\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(M):\n\u001b[1;32m    121\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(N):\n\u001b[0;32m--> 122\u001b[0m                 Power \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mg_tilde\u001b[49m[m, n] \u001b[38;5;241m*\u001b[39m ((x_extend[f, v, :, m]\u001b[38;5;241m*\u001b[39mpositive[f,v, m, n]\u001b[38;5;241m+\u001b[39mx_neg[f, v, :, m]\u001b[38;5;241m*\u001b[39mnegative[f,v, m, n])\u001b[38;5;241m-\u001b[39my[f, v, :, n])\u001b[38;5;241m.\u001b[39mpow(\u001b[38;5;241m2.\u001b[39m)\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m    123\u001b[0m Power \u001b[38;5;241m=\u001b[39m Power \u001b[38;5;241m/\u001b[39m E \u001b[38;5;241m/\u001b[39m V \u001b[38;5;241m/\u001b[39m F\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Power\n",
      "File \u001b[0;32m~/Desktop/TECO/24_Fault_Analysis/pNN.py:93\u001b[0m, in \u001b[0;36mpLayer.g_tilde\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mg_tilde\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;66;03m# scaled conductances\u001b[39;00m\n\u001b[1;32m     92\u001b[0m     g_initial \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtheta_\u001b[38;5;241m.\u001b[39mabs()\n\u001b[0;32m---> 93\u001b[0m     g_min \u001b[38;5;241m=\u001b[39m \u001b[43mg_initial\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     94\u001b[0m     scaler \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpgmin \u001b[38;5;241m/\u001b[39m g_min\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m g_initial \u001b[38;5;241m*\u001b[39m scaler\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lossfunction = pNN.pNNLoss(args).to(args.DEVICE)\n",
    "optimizer = torch.optim.Adam(pnn.GetParam(), lr=args.LR)\n",
    "\n",
    "if args.PROGRESSIVE:\n",
    "    pnn, best = train_pnn_progressive(pnn, train_loader, valid_loader, lossfunction, optimizer, args, msglogger, UUID=setup)\n",
    "else:\n",
    "    pnn, best = train_pnn(pnn, train_loader, valid_loader, lossfunction, optimizer, args, msglogger, UUID=setup)\n",
    "\n",
    "if best:\n",
    "    if not os.path.exists(f'{args.savepath}/'):\n",
    "        os.makedirs(f'{args.savepath}/')\n",
    "    torch.save(pnn, f'{args.savepath}/{setup}')\n",
    "    msglogger.info('Training if finished.')\n",
    "else:\n",
    "    msglogger.warning('Time out, further training is necessary.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pnn.model[0].INV.Mask = pnn.model[0].FaultMaskNEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pnn.model[0].INV.Mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvRT(torch.nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super().__init__()\n",
    "        self.args = args\n",
    "        self.N = args.N_train\n",
    "        self.epsilon = args.e_train\n",
    "        args.N_fault = args.N_fault\n",
    "\n",
    "        # R1, R2, R3, W1, L1, W2, L2, W3, L3\n",
    "        self.rt_ = torch.nn.Parameter(torch.tensor([args.NEG_R1n, args.NEG_R2n, args.NEG_R3n, args.NEG_W1n, args.NEG_L1n, args.NEG_W2n, args.NEG_L2n, args.NEG_W3n, args.NEG_L3n]).to(args.DEVICE), requires_grad=True)\n",
    "        # model\n",
    "        package = torch.load('./utils/neg_param.package')\n",
    "        self.eta_estimator = package['eta_estimator'].to(self.DEVICE)\n",
    "        self.eta_estimator.train(False)\n",
    "        for name, param in self.eta_estimator.named_parameters():\n",
    "            param.requires_grad = False\n",
    "        self.X_max = package['X_max'].to(self.DEVICE)\n",
    "        self.X_min = package['X_min'].to(self.DEVICE)\n",
    "        self.Y_max = package['Y_max'].to(self.DEVICE)\n",
    "        self.Y_min = package['Y_min'].to(self.DEVICE)\n",
    "        # load power model\n",
    "        package = torch.load('./utils/neg_power.package')\n",
    "        self.power_estimator = package['power_estimator'].to(self.DEVICE)\n",
    "        for name, param in self.power_estimator.named_parameters():\n",
    "            param.requires_grad = False\n",
    "        self.power_estimator.train(False)\n",
    "        self.pow_X_max = package['X_max'].to(self.DEVICE)\n",
    "        self.pow_X_min = package['X_min'].to(self.DEVICE)\n",
    "        self.pow_Y_max = package['Y_max'].to(self.DEVICE)\n",
    "        self.pow_Y_min = package['Y_min'].to(self.DEVICE)\n",
    "\n",
    "        self.eta_fault = torch.tensor([[ 8.3907e-01, -1.0000e+00,  0.0000e+00,  2.0978e-17],\n",
    "                                       [-6.0647e-01, -1.0000e+00,  0.0000e+00,  1.0867e-08],\n",
    "                                       [-9.9992e-01, -1.0000e+00,  0.0000e+00, -4.5596e-18],\n",
    "                                       [ 8.3907e-01, -1.0000e+00,  0.0000e+00, -1.8533e-17],\n",
    "                                       [ 3.1485e+01,  2.8551e-03, -9.9980e-02,  6.3016e+00],\n",
    "                                       [-1.0000e+00, -1.0000e+00,  0.0000e+00,  4.4070e-16],\n",
    "                                       [ 1.8307e+02, -1.8394e+02, -8.3575e+01,  4.2966e-02],\n",
    "                                       [-6.0647e-01, -1.0000e+00,  0.0000e+00,  1.0867e-08],\n",
    "                                       [ 1.2159e-01, -7.3578e-01, -7.9441e-02,  3.1090e+00],\n",
    "                                       [ 8.3907e-01, -1.0000e+00,  0.0000e+00,  2.0978e-17],\n",
    "                                       [-9.9992e-01, -1.0000e+00,  0.0000e+00, -4.5596e-18],\n",
    "                                       [ 7.6517e-01, -8.0291e-03,  6.3714e-01,  1.2184e+00],\n",
    "                                       [ 8.3907e-01, -1.0000e+00,  0.0000e+00,  2.0978e-17],\n",
    "                                       [ 8.3907e-01, -1.0000e+00,  0.0000e+00, -1.8533e-17],\n",
    "                                       [-1.0000e+00, -1.0000e+00,  0.0000e+00,  4.4070e-16],\n",
    "                                       [ 1.0000e+00, -1.0000e+00,  0.0000e+00,  4.4982e-16],\n",
    "                                       [-4.5913e-02, -7.2633e-01,  7.3493e-02,  1.0507e+01],\n",
    "                                       [-9.9992e-01, -1.0000e+00,  0.0000e+00, -4.5596e-18]]).to(self.DEVICE)\n",
    "\n",
    "        self.Mask = None\n",
    "\n",
    "    @property\n",
    "    def DEVICE(self):\n",
    "        return self.args.DEVICE\n",
    "    \n",
    "    @property\n",
    "    def RT(self):\n",
    "        # keep values in (0,1)\n",
    "        rt_temp = torch.sigmoid(self.rt_)\n",
    "        RTn = torch.zeros([12]).to(self.DEVICE)\n",
    "        RTn[:9] = rt_temp\n",
    "        # denormalization\n",
    "        RT = RTn * (self.X_max - self.X_min) + self.X_min\n",
    "        return RT\n",
    "    \n",
    "    @property\n",
    "    def RT_noisy(self):\n",
    "        RT_mean = self.RT.repeat(self.N, 1)\n",
    "        noise = ((torch.rand(RT_mean.shape) * 2. - 1.) * self.epsilon) + 1.\n",
    "        RT_variation = RT_mean * noise\n",
    "        return RT_variation\n",
    "\n",
    "    @property\n",
    "    def RTn_extend(self):\n",
    "        RT_extend = torch.stack([self.RT_noisy[:,0], self.RT_noisy[:,1], self.RT_noisy[:,2], self.RT_noisy[:,3],\n",
    "                                 self.RT_noisy[:,4], self.RT_noisy[:,5], self.RT_noisy[:,6], self.RT_noisy[:,7],\n",
    "                                 self.RT_noisy[:,8], self.RT_noisy[:,3]/self.RT_noisy[:,4], self.RT_noisy[:,5]/self.RT_noisy[:,6],\n",
    "                                 self.RT_noisy[:,7]/self.RT_noisy[:,8]], dim=1)\n",
    "        return (RT_extend - self.X_min) / (self.X_max - self.X_min)\n",
    "\n",
    "    @property\n",
    "    def eta(self):\n",
    "        # calculate eta\n",
    "        eta_n = self.eta_estimator(self.RTn_extend)\n",
    "        eta = eta_n * (self.Y_max - self.Y_min) + self.Y_min\n",
    "        return eta\n",
    "\n",
    "    @property\n",
    "    def power(self):\n",
    "        # calculate power\n",
    "        power_n = self.power_estimator(self.RTn_extend)\n",
    "        power = power_n * (self.pow_Y_max - self.pow_Y_min) + self.pow_Y_min\n",
    "        return power.mean()\n",
    "\n",
    "    def output_variation(self, eta, z):\n",
    "        a = torch.zeros_like(z)\n",
    "        for i in range(self.N):\n",
    "            a[i,:,:] = -(eta[i,0] + eta[i,1] * torch.tanh((z[i,:,:] - eta[i,2]) * eta[i,3]))\n",
    "        return a\n",
    "    \n",
    "    def output_faults(self, z, mask):\n",
    "        result = [self.output_variation(self.eta, z)]\n",
    "\n",
    "        for fault in range(self.eta_fault.shape[0]):\n",
    "            eta_temp = self.eta_fault[fault,:].repeat(self.N, 1)\n",
    "            result.append(self.output_variation(eta_temp, z))\n",
    "\n",
    "        output = torch.stack(result)\n",
    "        slices = [output[int(mask[i]), :, :, i] for i in range(mask.numel())]\n",
    "        return torch.stack(slices, dim=2)\n",
    "    \n",
    "    def forward(self, z):\n",
    "        result = []\n",
    "        for i in range(self.Mask.shape[0]):\n",
    "            result.append(self.output_faults(z[i,:,:,:], self.Mask[i]))\n",
    "        return torch.stack(result)\n",
    "    \n",
    "    def UpdateArgs(self, args):\n",
    "        self.args = args\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv = InvRT(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in train_loader:\n",
    "    break\n",
    "\n",
    "z  = x.repeat(args.N_fault, args.N_train, 1, 1)\n",
    "z = torch.randn(args.N_fault, args.N_train, 70, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = pnn.model[0].FaultMaskNEG\n",
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv.Mask = mask\n",
    "inv.output_faults(z[0,:,:,:], inv.Mask[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv.forward(z).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pnn.model[0].INV.Mask = mask\n",
    "pnn.model[0].INV.forward(z).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv.Mask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv(torch.Size([17, 10, 70, 8]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pnn.model[0].INV(torch.Size([17, 10, 70, 8]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
